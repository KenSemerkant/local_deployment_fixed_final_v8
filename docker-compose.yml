version: '3.8'

services:
  # Backend service
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    volumes:
      - ./backend:/app
      - data_volume:/data
    environment:
      - DATABASE_URL=sqlite:////data/db/financial_analyst.db
      - MINIO_ENDPOINT=minio:9000
      - MINIO_ACCESS_KEY=minioadmin
      - MINIO_SECRET_KEY=minioadmin
      - MINIO_SECURE=false
      - DOCUMENTS_BUCKET=documents
      - STORAGE_PATH=/data
      - LLM_MODE=openai  # Using LM Studio via OpenAI-compatible API
      - OPENAI_BASE_URL=http://host.docker.internal:1234/v1  # LM Studio default URL
      - OPENAI_API_KEY=lm-studio  # Can be any value for LM Studio
      - OPENAI_MODEL=deepseek-r1-0528-qwen3-8b-mlx  # DeepSeek model in LM Studio
      # Ollama settings (kept for easy switching back)
      # - OLLAMA_BASE_URL=http://host.docker.internal:11434
      # - OLLAMA_MODEL=deepseek-r1:14b
      # - OLLAMA_USE_CPU=false
      # - OLLAMA_MAX_TOKENS=20000
      - ENABLE_CACHING=true
    extra_hosts:
      - "host.docker.internal:host-gateway"
    depends_on:
      - minio
    restart: unless-stopped

  # Frontend service
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "3000:80"
    depends_on:
      - backend
    restart: unless-stopped

  # MinIO service (S3-compatible storage)
  minio:
    image: minio/minio
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio_data:/data
    environment:
      - MINIO_ROOT_USER=minioadmin
      - MINIO_ROOT_PASSWORD=minioadmin
    command: server /data --console-address ":9001"
    restart: unless-stopped

volumes:
  data_volume:
  minio_data:
